{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "za2nt3KXG1uP"
      },
      "outputs": [],
      "source": [
        "train_proteins = []\n",
        "train_peptides = []\n",
        "val_proteins = []\n",
        "val_peptides = []\n",
        "\n",
        "with open('/content/8_14_24_sequence_pairs_ALL.txt', 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    pro, pep, split = line.split(':')\n",
        "    if '0' in split:\n",
        "      train_proteins.append(pro)\n",
        "      train_peptides.append(pep)\n",
        "    else:\n",
        "      val_proteins.append(pro)\n",
        "      val_peptides.append(pep)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_proteins))\n",
        "print(len(train_peptides))\n",
        "print(len(val_proteins))\n",
        "print(len(val_peptides))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEcbC0vpH6RG",
        "outputId": "75be2f52-a09d-47c5-e65b-91dbfc66a091"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9668\n",
            "9668\n",
            "1118\n",
            "1118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame({'peptide': train_peptides, 'protein': train_proteins})\n",
        "val_df = pd.DataFrame({'peptide': val_peptides, 'protein': val_proteins})"
      ],
      "metadata": {
        "id": "NHELYu2bIGva"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_data_unique = train_df\n",
        "\n",
        "# Generate synthetic negative data by shuffling the 'Core' column\n",
        "shuffled_cores = selected_data_unique['peptide'].sample(frac=1, random_state=12).reset_index(drop=True)\n",
        "\n",
        "# Create a new DataFrame with the original 'Cyclase sequence' and the shuffled 'Core'\n",
        "negative_data = pd.DataFrame({\n",
        "  'protein': selected_data_unique['protein'],\n",
        "  'peptide': shuffled_cores\n",
        "})\n",
        "\n",
        "# Ensure there are no duplicates in the synthetic negative data compared to the original positive data\n",
        "negative_data_unique = negative_data.drop_duplicates()\n",
        "# negative_data_unique.to_csv('negative_cyclase_data.csv', index = False)\n",
        "\n",
        "# print(negative_data_unique)\n",
        "# Find common rows\n",
        "common_rows = pd.merge(selected_data_unique, negative_data_unique, on=['protein', 'peptide'], how='inner')\n",
        "\n",
        "# Print the common rows\n",
        "# print(\"Number of common rows:\", common_rows.shape[0])\n",
        "# print(common_rows)\n",
        "\n",
        "# Remove common rows from negative_data_unique\n",
        "negative_data_unique_clean = negative_data_unique[~negative_data_unique.apply(tuple, axis = 1).isin(common_rows.apply(tuple, axis=1))]\n",
        "# print(negative_data_unique_clean)\n",
        "\n",
        "combined_data = pd.concat([selected_data_unique, negative_data_unique_clean], ignore_index= True)\n",
        "# print(combined_data.shape)\n",
        "\n",
        "combined_data['label'] = selected_data_unique.shape[0] * [1] + negative_data_unique_clean.shape[0] * [0]\n",
        "combined_data.to_csv('training_pairs_spec.csv', index = False)"
      ],
      "metadata": {
        "id": "4O-XReHAIiVA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_data_unique = val_df\n",
        "\n",
        "# Generate synthetic negative data by shuffling the 'Core' column\n",
        "shuffled_cores = selected_data_unique['peptide'].sample(frac=1, random_state=12).reset_index(drop=True)\n",
        "\n",
        "# Create a new DataFrame with the original 'Cyclase sequence' and the shuffled 'Core'\n",
        "negative_data = pd.DataFrame({\n",
        "  'protein': selected_data_unique['protein'],\n",
        "  'peptide': shuffled_cores\n",
        "})\n",
        "\n",
        "# Ensure there are no duplicates in the synthetic negative data compared to the original positive data\n",
        "negative_data_unique = negative_data.drop_duplicates()\n",
        "# negative_data_unique.to_csv('negative_cyclase_data.csv', index = False)\n",
        "\n",
        "# print(negative_data_unique)\n",
        "# Find common rows\n",
        "common_rows = pd.merge(selected_data_unique, negative_data_unique, on=['protein', 'peptide'], how='inner')\n",
        "\n",
        "# Print the common rows\n",
        "# print(\"Number of common rows:\", common_rows.shape[0])\n",
        "# print(common_rows)\n",
        "\n",
        "# Remove common rows from negative_data_unique\n",
        "negative_data_unique_clean = negative_data_unique[~negative_data_unique.apply(tuple, axis = 1).isin(common_rows.apply(tuple, axis=1))]\n",
        "# print(negative_data_unique_clean)\n",
        "\n",
        "combined_data = pd.concat([selected_data_unique, negative_data_unique_clean], ignore_index= True)\n",
        "# print(combined_data.shape)\n",
        "\n",
        "combined_data['label'] = selected_data_unique.shape[0] * [1] + negative_data_unique_clean.shape[0] * [0]\n",
        "combined_data.to_csv('val_pairs_spec.csv', index = False)"
      ],
      "metadata": {
        "id": "NhRJoB2mJk5S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('val_pairs_spec.csv')\n",
        "sum(df['label'].tolist())/len(df['label'].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IFjiFPJJUAu",
        "outputId": "7f49ebc3-278c-4641-a0a4-23cfa64be236"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}