{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install neccesary packages\n",
        "!pip install biopython sparse\n",
        "\n",
        "# Download ProPedia structures\n",
        "!wget http://bioinfo.dcc.ufmg.br/propedia2/public/download/complex2_3.zip\n",
        "\n",
        "# Download ProPedia sequences\n",
        "!wget http://bioinfo.dcc.ufmg.br/propedia2/public/download/sequences2_3.zip\n",
        "\n",
        "# Unzip\n",
        "!unzip -qq /content/complex2_3.zip\n",
        "!unzip -qq /content/sequences2_3.zip"
      ],
      "metadata": {
        "id": "LwfDFavJNpHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f89bf38f-388d-47f6-fb64-82102f28d703"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting sparse\n",
            "  Downloading sparse-0.15.4-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from sparse) (1.13.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from sparse) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->sparse) (0.43.0)\n",
            "Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sparse-0.15.4-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.3/237.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython, sparse\n",
            "Successfully installed biopython-1.84 sparse-0.15.4\n",
            "--2024-11-16 01:37:15--  http://bioinfo.dcc.ufmg.br/propedia2/public/download/complex2_3.zip\n",
            "Resolving bioinfo.dcc.ufmg.br (bioinfo.dcc.ufmg.br)... 150.164.203.91\n",
            "Connecting to bioinfo.dcc.ufmg.br (bioinfo.dcc.ufmg.br)|150.164.203.91|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2524597712 (2.4G) [application/zip]\n",
            "Saving to: ‘complex2_3.zip’\n",
            "\n",
            "complex2_3.zip      100%[===================>]   2.35G  18.5MB/s    in 2m 37s  \n",
            "\n",
            "2024-11-16 01:39:53 (15.3 MB/s) - ‘complex2_3.zip’ saved [2524597712/2524597712]\n",
            "\n",
            "--2024-11-16 01:39:53--  http://bioinfo.dcc.ufmg.br/propedia2/public/download/sequences2_3.zip\n",
            "Resolving bioinfo.dcc.ufmg.br (bioinfo.dcc.ufmg.br)... 150.164.203.91\n",
            "Connecting to bioinfo.dcc.ufmg.br (bioinfo.dcc.ufmg.br)|150.164.203.91|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39569909 (38M) [application/zip]\n",
            "Saving to: ‘sequences2_3.zip’\n",
            "\n",
            "sequences2_3.zip    100%[===================>]  37.74M  11.7MB/s    in 3.2s    \n",
            "\n",
            "2024-11-16 01:39:57 (11.7 MB/s) - ‘sequences2_3.zip’ saved [39569909/39569909]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate sequence/contact data\n",
        "\n",
        "# Collect as many sequences as possible from propedia\n",
        "# Get their sequences and contact maps\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from Bio import SeqIO\n",
        "from Bio.PDB import PDBParser\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For storing data\n",
        "proteins = []\n",
        "peptides = []\n",
        "contacts = np.zeros((100_000, 52, 770))\n",
        "\n",
        "# Important parameters\n",
        "CUTOFF = 8\n",
        "maxPepLen = 50\n",
        "maxProLen = 768\n",
        "failed = 0\n",
        "\n",
        "with os.scandir('./complex') as it:\n",
        "  for entry in tqdm(it):\n",
        "    if entry.name.endswith(\".pdb\") and entry.is_file():\n",
        "        # Extract pdb id and chains\n",
        "        id, pepchain, prochain = entry.name.split('.')[0].split('_')\n",
        "\n",
        "        # Get peptide sequence\n",
        "        for record in SeqIO.parse(f\"./peptide/{id}_{pepchain}.fasta\", \"fasta\"):\n",
        "          pep_seq = str(record.seq)\n",
        "\n",
        "        # Get protein sequence\n",
        "        for record in SeqIO.parse(f\"./receptor/{id}_{prochain}.fasta\", \"fasta\"):\n",
        "          pro_seq = str(record.seq)\n",
        "\n",
        "        # Skip non-canonical amino acids, invalid lengths, etc\n",
        "        if 'X' in pep_seq or 'X' in pro_seq or len(pro_seq) > maxProLen:\n",
        "          continue\n",
        "\n",
        "        # Get pdb\n",
        "        parser = PDBParser()\n",
        "        structure = parser.get_structure('pdb', f'./complex/{entry.name}')\n",
        "        pep_chain = structure[0][pepchain]\n",
        "        pro_chain = structure[0][prochain]\n",
        "\n",
        "        # Select chains\n",
        "        pep_residues = [r for r in pep_chain.get_residues()]\n",
        "        rec_residues = [r for r in pro_chain.get_residues()]\n",
        "\n",
        "        # Skip if pdb sequence length is not fasta sequence len\n",
        "        if len(list(pep_chain.get_residues())) != len(pep_seq): continue\n",
        "        if len(list(pro_chain.get_residues())) != len(pro_seq): continue\n",
        "\n",
        "        # Get binary contact matrix\n",
        "        try:\n",
        "          distances = np.zeros((maxPepLen, maxProLen))\n",
        "          for x in range(min(len(pep_seq), maxPepLen)):\n",
        "            for y in range(min(len(pro_seq), maxProLen)):\n",
        "              one = pep_residues[x]['CA'].get_coord()\n",
        "              two = rec_residues[y]['CA'].get_coord()\n",
        "              d = np.linalg.norm(one-two)\n",
        "              if d <= CUTOFF:\n",
        "                distances[x, y] = 1\n",
        "              else:\n",
        "                distances[x, y] = 0\n",
        "        except:\n",
        "          failed += 1\n",
        "          # print(f'{failed} failed')\n",
        "          # print(f'{len(peptides)} succeeded')\n",
        "          # print(f'{contacts.sum()} total contacts')\n",
        "          continue\n",
        "\n",
        "        # Pad the out side of the matrix with 0's (to account for bos/eos)\n",
        "        distances = np.pad(distances, 1, 'constant', constant_values=(0))\n",
        "\n",
        "        if len(pro_seq) <= maxProLen and distances.sum() > 0:\n",
        "          peptides.append(pep_seq)\n",
        "          proteins.append(pro_seq)\n",
        "          contacts[len(peptides)-1] = distances"
      ],
      "metadata": {
        "id": "b4nnirjGPmbn",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contacts = contacts[:len(peptides)]\n",
        "print(len(peptides))\n",
        "print(len(proteins))\n",
        "contacts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gu-ODdQOAxe",
        "outputId": "0e88cb38-a6b2-4d7f-d14e-6a575d6e8a7e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15753\n",
            "15753\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15753, 52, 770)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate peptide/protein pairs.\n",
        "import sparse\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'sequence': peptides,\n",
        "    'receptor': proteins,\n",
        "    'contacts': list(range(contacts.shape[0]))\n",
        "})\n",
        "df = df.drop_duplicates(subset=[\"sequence\", \"receptor\"]).reset_index()\n",
        "contacts = contacts[df['contacts'].tolist()]\n",
        "\n",
        "proteins = df['receptor'].tolist()\n",
        "peptides = df['sequence'].tolist()\n",
        "\n",
        "print(len(proteins))\n",
        "print(len(peptides))\n",
        "print(contacts.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWkoJ26kg4Yp",
        "outputId": "8e46e4fa-bb1b-412a-a4f4-16f6eca94944"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10558\n",
            "10558\n",
            "(10558, 52, 770)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SAVE\n",
        "# Save the sequence pairs and the val indices.\n",
        "with open('11_15pairs.txt', 'w') as f:\n",
        "  for i, pair in enumerate(zip(peptides, proteins)):\n",
        "    p, P = pair\n",
        "    f.write(f'{P}:{p}:{0}\\n')\n",
        "f.close()\n",
        "np.savez_compressed('11_15contacts.npz', a=contacts)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "I5bumaOkFR1f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title If sequence/contact data is already generated, just load it directly\n",
        "# Load the protein/peptide pairs into lists\n",
        "import sparse\n",
        "import numpy as np\n",
        "proteins = []\n",
        "peptides = []\n",
        "with open('/content/8_8_24_sequence_pairs_768.txt', 'r') as f:\n",
        "  for line in f:\n",
        "    prot, pep, _ = line.split(':')\n",
        "    proteins.append(prot.replace('\\n', ''))\n",
        "    peptides.append(pep.replace('\\n', ''))\n",
        "f.close()\n",
        "\n",
        "# Load the distance matrices for all pairs\n",
        "sparse_contacts = sparse.load_npz('/content/8_8_24_contacts_768.npz')\n",
        "sparse_contacts = sparse_contacts[:len(peptides)]\n",
        "contacts = sparse_contacts.todense()\n",
        "\n",
        "print(len(peptides))\n",
        "print(len(proteins))\n",
        "contacts.shape"
      ],
      "metadata": {
        "id": "2uOSYn9Jg4z5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the the 10% of interfaces with the lowest\n",
        "# average similarity to all other interfaces\n",
        "\n",
        "contacts_flat = contacts.sum(axis=1)\n",
        "\n",
        "# Normalize embeddings\n",
        "norms = np.linalg.norm(contacts_flat, axis=1, keepdims=True)\n",
        "normalized_embeddings = contacts_flat / norms\n",
        "\n",
        "# Compute cosine similarities matrix\n",
        "cosine_similarities = np.dot(normalized_embeddings, normalized_embeddings.T)\n",
        "\n",
        "# Fill the diagonal with NaNs to ignore self-similarity\n",
        "np.fill_diagonal(cosine_similarities, np.nan)\n",
        "\n",
        "# Compute the average cosine similarity for each embedding\n",
        "average_similarities = np.nanmean(cosine_similarities, axis=1)\n",
        "\n",
        "# Find the indices of the 10% embeddings with the lowest average similarity\n",
        "# These sequences will become the validation set\n",
        "num_lowest = int(len(average_similarities) * 0.1)\n",
        "val_idxs = np.argsort(average_similarities)[:num_lowest]\n",
        "train_idxs = np.setdiff1d(np.arange(contacts_flat.shape[0]), val_idxs)"
      ],
      "metadata": {
        "id": "YgHrycndRVFQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, remove any sequence pairs that have distance matricies\n",
        "# with > 0.7 cosine similaity to any distance matrix in the validation set\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import manhattan_distances\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "cosine_similarities = 1 - cdist(contacts_flat[train_idxs], contacts_flat[val_idxs], metric='cosine')\n",
        "max_similarities = np.max(cosine_similarities, axis=1)\n",
        "train_idxs = train_idxs[np.where(max_similarities <= 0.7)[0]]\n",
        "\n",
        "print(train_idxs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w3KZl8Reun2",
        "outputId": "b3f191fe-6f61-4058-ed96-641881ea14e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9112,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_idxs = np.concatenate((train_idxs, val_idxs), axis=0)\n",
        "contacts = contacts[all_idxs]\n",
        "\n",
        "print(len(peptides))\n",
        "print(len(proteins))\n",
        "contacts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isEezEUl0S6X",
        "outputId": "b6bd0f9f-3495-4212-9a41-d1b2bd77346c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10558\n",
            "10558\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10167, 52, 770)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the sequence pairs and the val indices.\n",
        "with open('PepFusionSequencePairs.txt', 'w') as f:\n",
        "  for i, pair in enumerate(zip(peptides, proteins)):\n",
        "    p, P = pair\n",
        "    if i in val_idxs:\n",
        "      f.write(f'{P}:{p}:{1}\\n')\n",
        "    elif i in train_idxs:\n",
        "      f.write(f'{P}:{p}:{0}\\n')\n",
        "f.close()"
      ],
      "metadata": {
        "id": "B6p_tJvZiX-3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez_compressed('PepFusionContacts.npz', a=contacts)"
      ],
      "metadata": {
        "id": "pD-s2CyIi3Mr"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}